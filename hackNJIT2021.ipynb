{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZS7D165onbsf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/utkarshchandra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/utkarshchandra/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/utkarshchandra/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/utkarshchandra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/utkarshchandra/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/utkarshchandra/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus.reader.wordnet import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "worddict = set(nltk.corpus.words.words())\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "As8yPFjpqMWL"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('usbank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8PgRpTU1qlXi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>User</th>\n",
       "      <th>User_statuses_count</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>fav_count</th>\n",
       "      <th>User_location</th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#NeverOutOfTown</td>\n",
       "      <td>4253</td>\n",
       "      <td>563</td>\n",
       "      <td>0</td>\n",
       "      <td>Any City, USA</td>\n",
       "      <td>RT @BOAStadiumWx: Bank of America Stadium at s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DEE</td>\n",
       "      <td>22221</td>\n",
       "      <td>2627</td>\n",
       "      <td>0</td>\n",
       "      <td>Virginia! USA</td>\n",
       "      <td>RT @CIG_KingJames: Dear God, \\nPlease Save Ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BigJayy üòé</td>\n",
       "      <td>126088</td>\n",
       "      <td>2300</td>\n",
       "      <td>0</td>\n",
       "      <td>2Ô∏è‚É£5Ô∏è‚É£2Ô∏è‚É£</td>\n",
       "      <td>RT @El_Liaison: Wonder how electric Bank Of Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Always a Trumpster!</td>\n",
       "      <td>92483</td>\n",
       "      <td>3706</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @CIG_KingJames: Dear God, \\nPlease Save Ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Whitney Hakim</td>\n",
       "      <td>1818</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Injustices4All @rossyrosay @BankofAmerica @of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 User  User_statuses_count  user_followers  \\\n",
       "0           0      #NeverOutOfTown                 4253             563   \n",
       "1           1                  DEE                22221            2627   \n",
       "2           2            BigJayy üòé               126088            2300   \n",
       "3           3  Always a Trumpster!                92483            3706   \n",
       "4           4        Whitney Hakim                 1818             161   \n",
       "\n",
       "   fav_count  User_location                                             Tweets  \n",
       "0          0  Any City, USA  RT @BOAStadiumWx: Bank of America Stadium at s...  \n",
       "1          0  Virginia! USA  RT @CIG_KingJames: Dear God, \\nPlease Save Ame...  \n",
       "2          0      2Ô∏è‚É£5Ô∏è‚É£2Ô∏è‚É£  RT @El_Liaison: Wonder how electric Bank Of Am...  \n",
       "3          0            NaN  RT @CIG_KingJames: Dear God, \\nPlease Save Ame...  \n",
       "4          0            NaN  @Injustices4All @rossyrosay @BankofAmerica @of...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5lMWjNBUD_Uk"
   },
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RANLQFTjuZyL"
   },
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    wordset_n = set(wn.lemmatize(w, wordnet.NOUN) for w in word_tokenize(text.lower().strip()))\n",
    "    wordset_v = set(wn.lemmatize(w, wordnet.VERB) for w in wordset_n)\n",
    "    wordset = set(wn.lemmatize(w, wordnet.ADJ) for w in wordset_v)\n",
    "    wordset = wordset & worddict\n",
    "    return ' '.join(list(wordset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZxK_Ke-q-fws"
   },
   "outputs": [],
   "source": [
    "df['text']=df['Tweets'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "wvxI9wL_CiwN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>User</th>\n",
       "      <th>User_statuses_count</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>fav_count</th>\n",
       "      <th>User_location</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#NeverOutOfTown</td>\n",
       "      <td>4253</td>\n",
       "      <td>563</td>\n",
       "      <td>0</td>\n",
       "      <td>Any City, USA</td>\n",
       "      <td>RT @BOAStadiumWx: Bank of America Stadium at s...</td>\n",
       "      <td>at it bank and stadium sunset of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DEE</td>\n",
       "      <td>22221</td>\n",
       "      <td>2627</td>\n",
       "      <td>0</td>\n",
       "      <td>Virginia! USA</td>\n",
       "      <td>RT @CIG_KingJames: Dear God, \\nPlease Save Ame...</td>\n",
       "      <td>save the get god central please bank dear worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BigJayy üòé</td>\n",
       "      <td>126088</td>\n",
       "      <td>2300</td>\n",
       "      <td>0</td>\n",
       "      <td>2Ô∏è‚É£5Ô∏è‚É£2Ô∏è‚É£</td>\n",
       "      <td>RT @El_Liaison: Wonder how electric Bank Of Am...</td>\n",
       "      <td>how happen be wonder moment when will bank sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Always a Trumpster!</td>\n",
       "      <td>92483</td>\n",
       "      <td>3706</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @CIG_KingJames: Dear God, \\nPlease Save Ame...</td>\n",
       "      <td>save the get god central please bank dear worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Whitney Hakim</td>\n",
       "      <td>1818</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Injustices4All @rossyrosay @BankofAmerica @of...</td>\n",
       "      <td>get end elsewhere i give up finance like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 User  User_statuses_count  user_followers  \\\n",
       "0           0      #NeverOutOfTown                 4253             563   \n",
       "1           1                  DEE                22221            2627   \n",
       "2           2            BigJayy üòé               126088            2300   \n",
       "3           3  Always a Trumpster!                92483            3706   \n",
       "4           4        Whitney Hakim                 1818             161   \n",
       "\n",
       "   fav_count  User_location  \\\n",
       "0          0  Any City, USA   \n",
       "1          0  Virginia! USA   \n",
       "2          0      2Ô∏è‚É£5Ô∏è‚É£2Ô∏è‚É£   \n",
       "3          0            NaN   \n",
       "4          0            NaN   \n",
       "\n",
       "                                              Tweets  \\\n",
       "0  RT @BOAStadiumWx: Bank of America Stadium at s...   \n",
       "1  RT @CIG_KingJames: Dear God, \\nPlease Save Ame...   \n",
       "2  RT @El_Liaison: Wonder how electric Bank Of Am...   \n",
       "3  RT @CIG_KingJames: Dear God, \\nPlease Save Ame...   \n",
       "4  @Injustices4All @rossyrosay @BankofAmerica @of...   \n",
       "\n",
       "                                                text  \n",
       "0                   at it bank and stadium sunset of  \n",
       "1  save the get god central please bank dear worl...  \n",
       "2  how happen be wonder moment when will bank sta...  \n",
       "3  save the get god central please bank dear worl...  \n",
       "4           get end elsewhere i give up finance like  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "9UuaxMTtHKSx"
   },
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-GDK1QW1H0wa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>User</th>\n",
       "      <th>User_statuses_count</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>fav_count</th>\n",
       "      <th>User_location</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>text</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#NeverOutOfTown</td>\n",
       "      <td>4253</td>\n",
       "      <td>563</td>\n",
       "      <td>0</td>\n",
       "      <td>Any City, USA</td>\n",
       "      <td>RT @BOAStadiumWx: Bank of America Stadium at s...</td>\n",
       "      <td>at it bank and stadium sunset of</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DEE</td>\n",
       "      <td>22221</td>\n",
       "      <td>2627</td>\n",
       "      <td>0</td>\n",
       "      <td>Virginia! USA</td>\n",
       "      <td>RT @CIG_KingJames: Dear God, \\nPlease Save Ame...</td>\n",
       "      <td>save the get god central please bank dear worl...</td>\n",
       "      <td>{'neg': 0.186, 'neu': 0.381, 'pos': 0.432, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BigJayy üòé</td>\n",
       "      <td>126088</td>\n",
       "      <td>2300</td>\n",
       "      <td>0</td>\n",
       "      <td>2Ô∏è‚É£5Ô∏è‚É£2Ô∏è‚É£</td>\n",
       "      <td>RT @El_Liaison: Wonder how electric Bank Of Am...</td>\n",
       "      <td>how happen be wonder moment when will bank sta...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Always a Trumpster!</td>\n",
       "      <td>92483</td>\n",
       "      <td>3706</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @CIG_KingJames: Dear God, \\nPlease Save Ame...</td>\n",
       "      <td>save the get god central please bank dear worl...</td>\n",
       "      <td>{'neg': 0.186, 'neu': 0.381, 'pos': 0.432, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Whitney Hakim</td>\n",
       "      <td>1818</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Injustices4All @rossyrosay @BankofAmerica @of...</td>\n",
       "      <td>get end elsewhere i give up finance like</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.706, 'pos': 0.294, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 User  User_statuses_count  user_followers  \\\n",
       "0           0      #NeverOutOfTown                 4253             563   \n",
       "1           1                  DEE                22221            2627   \n",
       "2           2            BigJayy üòé               126088            2300   \n",
       "3           3  Always a Trumpster!                92483            3706   \n",
       "4           4        Whitney Hakim                 1818             161   \n",
       "\n",
       "   fav_count  User_location  \\\n",
       "0          0  Any City, USA   \n",
       "1          0  Virginia! USA   \n",
       "2          0      2Ô∏è‚É£5Ô∏è‚É£2Ô∏è‚É£   \n",
       "3          0            NaN   \n",
       "4          0            NaN   \n",
       "\n",
       "                                              Tweets  \\\n",
       "0  RT @BOAStadiumWx: Bank of America Stadium at s...   \n",
       "1  RT @CIG_KingJames: Dear God, \\nPlease Save Ame...   \n",
       "2  RT @El_Liaison: Wonder how electric Bank Of Am...   \n",
       "3  RT @CIG_KingJames: Dear God, \\nPlease Save Ame...   \n",
       "4  @Injustices4All @rossyrosay @BankofAmerica @of...   \n",
       "\n",
       "                                                text  \\\n",
       "0                   at it bank and stadium sunset of   \n",
       "1  save the get god central please bank dear worl...   \n",
       "2  how happen be wonder moment when will bank sta...   \n",
       "3  save the get god central please bank dear worl...   \n",
       "4           get end elsewhere i give up finance like   \n",
       "\n",
       "                                              scores  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "1  {'neg': 0.186, 'neu': 0.381, 'pos': 0.432, 'co...  \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "3  {'neg': 0.186, 'neu': 0.381, 'pos': 0.432, 'co...  \n",
       "4  {'neg': 0.0, 'neu': 0.706, 'pos': 0.294, 'comp...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scores'] = df['text'].apply(lambda text: sid.polarity_scores(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "nKYVibR7H9xM"
   },
   "outputs": [],
   "source": [
    "df['compound'] = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "df['sentiment_type']=''\n",
    "df.loc[df.compound>0,'sentiment_type']='POSITIVE'\n",
    "df.loc[df.compound==0,'sentiment_type']='NEUTRAL'\n",
    "df.loc[df.compound<0,'sentiment_type']='NEGATIVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "M-7yLuu-IDUN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>User</th>\n",
       "      <th>User_statuses_count</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>fav_count</th>\n",
       "      <th>User_location</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>text</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#NeverOutOfTown</td>\n",
       "      <td>4253</td>\n",
       "      <td>563</td>\n",
       "      <td>0</td>\n",
       "      <td>Any City, USA</td>\n",
       "      <td>RT @BOAStadiumWx: Bank of America Stadium at s...</td>\n",
       "      <td>at it bank and stadium sunset of</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DEE</td>\n",
       "      <td>22221</td>\n",
       "      <td>2627</td>\n",
       "      <td>0</td>\n",
       "      <td>Virginia! USA</td>\n",
       "      <td>RT @CIG_KingJames: Dear God, \\nPlease Save Ame...</td>\n",
       "      <td>save the get god central please bank dear worl...</td>\n",
       "      <td>{'neg': 0.186, 'neu': 0.381, 'pos': 0.432, 'co...</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BigJayy üòé</td>\n",
       "      <td>126088</td>\n",
       "      <td>2300</td>\n",
       "      <td>0</td>\n",
       "      <td>2Ô∏è‚É£5Ô∏è‚É£2Ô∏è‚É£</td>\n",
       "      <td>RT @El_Liaison: Wonder how electric Bank Of Am...</td>\n",
       "      <td>how happen be wonder moment when will bank sta...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Always a Trumpster!</td>\n",
       "      <td>92483</td>\n",
       "      <td>3706</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @CIG_KingJames: Dear God, \\nPlease Save Ame...</td>\n",
       "      <td>save the get god central please bank dear worl...</td>\n",
       "      <td>{'neg': 0.186, 'neu': 0.381, 'pos': 0.432, 'co...</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Whitney Hakim</td>\n",
       "      <td>1818</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Injustices4All @rossyrosay @BankofAmerica @of...</td>\n",
       "      <td>get end elsewhere i give up finance like</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.706, 'pos': 0.294, 'comp...</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 User  User_statuses_count  user_followers  \\\n",
       "0           0      #NeverOutOfTown                 4253             563   \n",
       "1           1                  DEE                22221            2627   \n",
       "2           2            BigJayy üòé               126088            2300   \n",
       "3           3  Always a Trumpster!                92483            3706   \n",
       "4           4        Whitney Hakim                 1818             161   \n",
       "\n",
       "   fav_count  User_location  \\\n",
       "0          0  Any City, USA   \n",
       "1          0  Virginia! USA   \n",
       "2          0      2Ô∏è‚É£5Ô∏è‚É£2Ô∏è‚É£   \n",
       "3          0            NaN   \n",
       "4          0            NaN   \n",
       "\n",
       "                                              Tweets  \\\n",
       "0  RT @BOAStadiumWx: Bank of America Stadium at s...   \n",
       "1  RT @CIG_KingJames: Dear God, \\nPlease Save Ame...   \n",
       "2  RT @El_Liaison: Wonder how electric Bank Of Am...   \n",
       "3  RT @CIG_KingJames: Dear God, \\nPlease Save Ame...   \n",
       "4  @Injustices4All @rossyrosay @BankofAmerica @of...   \n",
       "\n",
       "                                                text  \\\n",
       "0                   at it bank and stadium sunset of   \n",
       "1  save the get god central please bank dear worl...   \n",
       "2  how happen be wonder moment when will bank sta...   \n",
       "3  save the get god central please bank dear worl...   \n",
       "4           get end elsewhere i give up finance like   \n",
       "\n",
       "                                              scores  compound sentiment_type  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000        NEUTRAL  \n",
       "1  {'neg': 0.186, 'neu': 0.381, 'pos': 0.432, 'co...    0.5859       POSITIVE  \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000        NEUTRAL  \n",
       "3  {'neg': 0.186, 'neu': 0.381, 'pos': 0.432, 'co...    0.5859       POSITIVE  \n",
       "4  {'neg': 0.0, 'neu': 0.706, 'pos': 0.294, 'comp...    0.3612       POSITIVE  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "IwQnMjwxIE2Z"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], df['sentiment_type'], test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "viq5EQHBIYEO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass alpha=1.0, fit_prior=True, class_prior=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "tf_transformer = TfidfTransformer(use_idf=False) # just use tf, no idf used\n",
    "\n",
    "# convert the text list to tfidf form matrix\n",
    "x_train_counts = count_vect.fit_transform(x_train)\n",
    "x_train_tf = tf_transformer.fit_transform(x_train_counts)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "clf = MultinomialNB(1.0, True, None)\n",
    "clf.fit(x_train_tf, y_train) # train the classifier\n",
    "\n",
    "# convert list to matrix\n",
    "x_pre_counts = count_vect.transform(x_test)\n",
    "x_pre_tf = tf_transformer.transform(x_pre_counts)\n",
    "\n",
    "predicted = clf.predict(x_pre_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "55cGDyfKLJD2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8011695906432749"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(list(y_test), predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "UBUbU0p-LMpH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 34,  16,  21],\n",
       "       [  0, 114,  16],\n",
       "       [  0,  15, 126]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(list(y_test), predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "JpfKq3g4LWBR"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FTJGlmizLbjd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.890399</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.030655</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.71875</td>\n",
       "      <td>0.798742</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.786753</td>\n",
       "      <td>0.034834</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.753894</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>0.020133</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.805031</td>\n",
       "      <td>0.767296</td>\n",
       "      <td>0.761006</td>\n",
       "      <td>0.781667</td>\n",
       "      <td>0.035348</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.037072</td>\n",
       "      <td>0.015088</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.71250</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.798742</td>\n",
       "      <td>0.767296</td>\n",
       "      <td>0.780472</td>\n",
       "      <td>0.037696</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.857295</td>\n",
       "      <td>0.052611</td>\n",
       "      <td>0.031306</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.72500</td>\n",
       "      <td>0.786164</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.767296</td>\n",
       "      <td>0.780456</td>\n",
       "      <td>0.032436</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.423771</td>\n",
       "      <td>0.009096</td>\n",
       "      <td>0.017005</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.73125</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.798742</td>\n",
       "      <td>0.767296</td>\n",
       "      <td>0.780448</td>\n",
       "      <td>0.028634</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8        0.890399      0.054500         0.030655        0.003432   \n",
       "11       0.753894      0.012022         0.020133        0.001543   \n",
       "4        0.416667      0.037072         0.015088        0.002497   \n",
       "5        0.857295      0.052611         0.031306        0.003944   \n",
       "10       0.423771      0.009096         0.017005        0.006481   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "8               90                300   \n",
       "11            None                300   \n",
       "4               60                150   \n",
       "5               60                300   \n",
       "10            None                150   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "8     {'max_depth': 90, 'n_estimators': 300}             0.8125   \n",
       "11  {'max_depth': None, 'n_estimators': 300}             0.8375   \n",
       "4     {'max_depth': 60, 'n_estimators': 150}             0.8125   \n",
       "5     {'max_depth': 60, 'n_estimators': 300}             0.8125   \n",
       "10  {'max_depth': None, 'n_estimators': 150}             0.8125   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "8             0.71875           0.798742           0.811321   \n",
       "11            0.73750           0.805031           0.767296   \n",
       "4             0.71250           0.811321           0.798742   \n",
       "5             0.72500           0.786164           0.811321   \n",
       "10            0.73125           0.792453           0.798742   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "8            0.792453         0.786753        0.034834                1  \n",
       "11           0.761006         0.781667        0.035348                2  \n",
       "4            0.767296         0.780472        0.037696                3  \n",
       "5            0.767296         0.780456        0.032436                4  \n",
       "10           0.767296         0.780448        0.028634                5  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 150, 300],\n",
    "        'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)# n_jobs=-1 for parallelizing search\n",
    "gs_fit = gs.fit(x_train_tf, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "VQuMYBjILhWP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421052631578947"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=150, max_depth=60, random_state=0)\n",
    "clf.fit(x_train_tf, y_train)\n",
    "predicted = clf.predict(x_pre_tf)\n",
    "metrics.accuracy_score(list(y_test), predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "5gYtgbZtLypp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 47,  16,   8],\n",
       "       [  1, 111,  18],\n",
       "       [  0,  11, 130]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(list(y_test), predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4VvcLpJlL-dN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "hackNJIT2021.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
